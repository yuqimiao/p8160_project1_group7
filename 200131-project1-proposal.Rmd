---
title: "p8160-project1"
output: word_document
---

# 1 Objectives 
Design a simulation study to investigate and illustrate 
how well each of the two methods in identifying weak and strong predictors;
how missing “weak” predictors impacts the parameter estimations. 
To do so, you need to simulate data with a combination of strong'',weak-but-correlated” and “weak-and- independent” predictors. 

# 2 Statistical methods to be studied 

## 2.1 Step-wise forward method

Starting with the empty model, and iteratively adds the variables that best improves the model fit. That is often done by sequentially adding predictors with the largest reduction in AIC. For linear models,
$$AIC=n\ln(\sum_{i=1}^n{(y_i-\widehat{y_i})}^2/n)+2p$$
where $\widehat{y_i}$ is the fitted values from a model, and $p$ is the dimension of the model (i.e.,number of predictors plus 1).

## 2.2 Automated LASSO regression LASSO

another popular method for variable selection. It estimates the model parameters by optimizing a penalized loss function:

$$\underset\beta{min}\frac{1}{2n}\sum_{i=1}^n(y_i-x_i\beta)^2+\lambda\sum_{k=1}^p|\beta_k|$$
where $\lambda$ is a tunning parameter. Cross-validation (CV) is the most common selection criteria for LASSO.


# 3 Scenarios to be investigated 

* weak-to-strong predictor ratio;


# 4 Methods for generating data 


# 5 performance measures 
## 5.1 Predictor identification performance

In order to compare the performance on identify weak and strong parameters,  F1 scores for weak-but-correlated, weak-and-independent and strong predictors identification was constructed:

$$F_1=\left(\frac{2}{recall^{-1}+precision^{-1}}\right)$$
For strong $F_1$ score as example, Where recall is defined as the ratio of truely identified strong predictors to all true strong ones, precision is defined as the ratio of true strong predictors to all predicted strong ones. $F_1$ score is defined as the harmonic mean of these two ratio, which illustrates the strong predictors identification ability of two methods.

Weak predictors are partitioned into 2 categoris and the F_1 score were calculated separately in weak_and_independent and weak_but_correlated groups, compare the score to evaluate the ability between 2 groups, conceptually, the weak but corelated should have a higher error since linear correlated with strong predictors.


## 5.2 estimation performance

To compare the paramater estimation performance, 3 indicators were calculated to evaluate the estimation: bias is calculated as the mean difference between true parameter and estimated parameters, variance is defined as the variance of the estimated parameter among simulation, and MSE

By tuning parameters differently, robustness of the variable selection methods were also evaluated through the above indicators.


# 6 simulation results. 

## 6.1 tuning predictor numbers
* identification F1 score
* bias, variance and MSE
* summary
## 6.2 tuning strong-to-weak ratio of predictors

## 6.3 tuning the degree of correlation

## 6.4 tunning samplesize

## 7 summary



